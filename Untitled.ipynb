{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import unidecode\n",
    "\n",
    "\n",
    "from parser import *\n",
    "from img_preproc import *\n",
    "from img_utils import *\n",
    "from tes_ocr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc1(img):\n",
    "    gray_img = get_grayscale(img)\n",
    "    bin_img = to_bin(gray_img)\n",
    "    # th_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 8)\n",
    "\n",
    "    h, status = get_ticket_homography(bin_img)\n",
    "    hom_gray_img =  cv2.warpPerspective(gray_img, h, (gray_img.shape[1],gray_img.shape[0]))\n",
    "    hom_bin_img =  cv2.warpPerspective(bin_img, h, (bin_img.shape[1],bin_img.shape[0]))\n",
    "\n",
    "    T_bounds = get_T_bounds2(hom_bin_img)\n",
    "\n",
    "    out = hom_gray_img[:, T_bounds[0]:]\n",
    "    show([img, bin_img, hom_bin_img, out], .2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c323c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_texts = {}\n",
    "ocr_scale = 0.3\n",
    "for img_path in tqdm(Path('data/receipt1').iterdir()):\n",
    "    if img_path.name == '3.JPG':\n",
    "        continue\n",
    "    print('Loading Image', img_path.name)\n",
    "    \n",
    "    img = cv2.imread(str(img_path))\n",
    "    preproc_img = preproc1(img)\n",
    "    ocr_img = resize(preproc_img, ocr_scale)\n",
    "\n",
    "    df_ocr = get_ocr(ocr_img)\n",
    "    df_ocr = postprocess_ocr(df_ocr)\n",
    "    ocr_text = extract_text(df_ocr)\n",
    "    ocr_text = list(map(unidecode.unidecode, ocr_text))  # Removes accents\n",
    "    list(map(print, ocr_text))    \n",
    "    \n",
    "    monoparser = MonoprixParser()\n",
    "    monoparser.parse_monoprix(ocr_text)\n",
    "    display(monoparser.df_articles)\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_img = get_color(ocr_img)\n",
    "for i,row in df_ocr[df_ocr.level == 5].iterrows():\n",
    "    beg = (row['left'], row['top'])\n",
    "    end = (row['left'] + row['width'], row['top']+row['height'])\n",
    "    col_img = cv2.rectangle(col_img, beg, end, (0, 255, 0), 2)\n",
    "show([col_img], scale=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocr[df_ocr.level==5].plot.scatter('left', 'top')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "df_info[~df_info.text.isna()].sort_values('height').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr-venv",
   "language": "python",
   "name": "ocr-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}